import os
import random

import torch
from torch.utils.data import DataLoader, Dataset

import re
from tokenizers import Tokenizer

from typing import List, Any, Tuple

def load_data(tokenization_level: str, model_type: str):
    """
    Function for loading data for language modeling and WER computation. You
    may modify the function header and outputs as necessary.

    Inputs:
        tokenization_level (str): The level at which to tokenize the input
        model_type (str): n_gram or transformer
    """
    # TODO
    return [], [], [], [], [], []



        
